{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRARIES\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#DEFINING CLASSES\n",
    "class Sentiment:\n",
    "  NEGATIVE = 'NEGATIVE'\n",
    "  POSITIVE = 'POSITIVE'\n",
    "\n",
    "class Review:\n",
    "  def __init__(self,text,score):\n",
    "    self.text = text\n",
    "    self.score = score\n",
    "    self.sentiment = self.get_sentiment()\n",
    "\n",
    "  def get_sentiment(self):\n",
    "    if self.score == 0:\n",
    "      return Sentiment.NEGATIVE\n",
    "    else:\n",
    "      return Sentiment.POSITIVE\n",
    "\n",
    "class ReviewContainer:\n",
    "  def __init__(self, reviews):\n",
    "    self.reviews = reviews\n",
    "\n",
    "  def get_text(self):\n",
    "    return [x.text for x in self.reviews]\n",
    "\n",
    "  def get_sentiment(self):\n",
    "    return [x.sentiment for x in self.reviews]\n",
    "\n",
    "  def evenly_distribute(self):\n",
    "    negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "    positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "    positive_shrunk = positive[:2500]\n",
    "    negative_shrunk = negative[:2500]\n",
    "    self.reviews = negative_shrunk + positive_shrunk\n",
    "    random.shuffle(self.reviews)\n",
    "    \n",
    "def TestingReviews(amount=5):\n",
    "    list_rand = []\n",
    "    limit = len(test_data)\n",
    "    rand_row = random.randrange(amount, limit, 1)\n",
    "    for n in range(amount):\n",
    "        rand_row = random.randrange(0, limit, 1)\n",
    "        row_to_test = [test_data.user_review[rand_row]]\n",
    "        row_test = vectorizer.transform(row_to_test)\n",
    "        print(row_to_test)\n",
    "        print(clf_svc.predict(row_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-tyler",
   "metadata": {},
   "source": [
    "### DEFINING AND PREPARING THE DATA\n",
    "\n",
    "We will load our train reviews (CSV file) and apply a filter to just use the two columns we need to train our model - user_suggestion and user_review. We will append the values using our Review class.\n",
    "\n",
    "We will also rename those columns to make it easier to work with them. If needed, we will need to evenly distribute values to avoid bias in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sunset-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train_reviews.csv')\n",
    "\n",
    "#TEST DATA FOR FURTHER TESTING\n",
    "test_data = pd.read_csv('./data/test_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "norwegian-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.rename(columns={\"recommendation\": \"score\", \"review\": \"text\"})\n",
    "df_train = df_train.filter(['text','score'])\n",
    "df_train['score'] = df_train['score'].replace('Not Recommended',0).replace('Recommended',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING SPECIAL CHARACTERS, WHICH MAY CONFUSE THE MODEL\n",
    "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "              \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\"]\n",
    "\n",
    "for char in spec_chars:\n",
    "    df_train['text'] = df_train['text'].str.replace(char, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "personalized-operator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "above-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "  reviews.append(Review(row['text'], row['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reverse-canvas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text\n",
       "score        \n",
       "0      130624\n",
       "1      302751"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('score').count() #MIGHT NEED TO BALANCE 0 AND 1 TO TRAIN THE MODEL BETTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-happening",
   "metadata": {},
   "source": [
    "### DEFINING THE MODEL AND TRAINING\n",
    "\n",
    "From previous experience, a support-vector machine model provides the best results for user reviews. However, we will test Decision Trees too to evaluate the output with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "utility-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = train_test_split(reviews, test_size=0.2, random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afraid-leather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment() \n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-plasma",
   "metadata": {},
   "source": [
    "#### VECTORISING THE DATA\n",
    "\n",
    "We will use a Count Vectorizer and a Tfidf Vectorizer and evaluate which delivers the best prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eleven-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-sacramento",
   "metadata": {},
   "source": [
    "#### SVM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "crude-distributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-building",
   "metadata": {},
   "source": [
    "#### DECISION TREE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "headed-farming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 971 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-discretion",
   "metadata": {},
   "source": [
    "#### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "threaded-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_nb = GaussianNB()\n",
    "# clf_nb.fit(train_x_vectors.todense(), train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-springer",
   "metadata": {},
   "source": [
    "#### MEAN ACCURACY OF EACH MODEL & F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brutal-dylan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8278\n",
      "0.714\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "#print(clf_nb.score(test_x_vectors.todense(), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wound-davis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82797203 0.82762763]\n",
      "[0.7080441  0.71971776]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "#print(f1_score(test_y, clf_nb.predict(test_x_vectors.todense()), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-refund",
   "metadata": {},
   "source": [
    "### GRID SEARCH\n",
    "Optimising the model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "naughty-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'kernel': ('linear','rbf'), 'C': (1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf_svc = GridSearchCV(svc, parameters, cv=5)\n",
    "\n",
    "clf_svc.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nervous-appearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827\n"
     ]
    }
   ],
   "source": [
    "print(clf_svc.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hazardous-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30,\n",
       "                                       40, 50, 70, 90, 120, 150]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "\n",
    "clf_gridtree = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5)\n",
    "clf_gridtree.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "subsequent-subsection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7225\n"
     ]
    }
   ],
   "source": [
    "print(clf_gridtree.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-aggregate",
   "metadata": {},
   "source": [
    "### FURTHER TESTING\n",
    "\n",
    "You have to options to test the model: input your own text (a review) or runt the TestingReviews function and it will randomly pick X amount of indenpent reviews (not part of the training model) to categorise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "entitled-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SINGLE TESTING A SHORT REVIEW\n",
    "test_set = ['I was a bit confused about the gameplay so I didnt enjoyed the game this time, even though the sequel was great']\n",
    "\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_svc.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "identical-sampling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Early Access ReviewOpen the game crash, open it again works well.Jump into a game try to land, see a car, land on the car, fall into the ground.After you rage you come back to the game, land, see an AR try to take it immediately get two tapped by R380.New case, buy them all, get sh*t, repeat when another come out.11/10 IGN will suicide again']\n",
      "['POSITIVE']\n",
      "['So i found this game on my recommendation tab.I thought \"Oh another Weaboo game, let\\'s try it\"First 10 minutes playing : Too slow, need some hacks-----Hacks Initiated------Stats : MaxedJobs : MaxedMultiplier : 1.00xParents : 10000% Ashamed-------Auto Click Online-----Passion : MaxedMoney : High but not maxedGifts: Can\\'t afford a shoe being an astronautHands: Free as can beResult : I got dishonred, kicked out and expelled from my building. All that in less than 3 hours.10/10 Would do everything again.']\n",
      "['POSITIVE']\n",
      "[\"Thank god i didn't waste money with this game.Too many technical issues that makes this game unplayable, literally. I mean, i currently can't login due to a connection bug that happens when you enter in some specific dungeons and it's been like this for days.Now besides not being unable to log in, i need to wait in a 700+ queue for every _failed_ connection attempt. I just got mad, uninstalled.0/10 - Would never play again.\"]\n",
      "['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "#RUN THIS FUCTION (REVIEWS TO BE TESTED ARE 5 BY DEFAULT) TO TRY THE MODEL WITH A DIFFERENT REVIEWS DATASET\n",
    "TestingReviews(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-father",
   "metadata": {},
   "source": [
    "### SAVING THE MODEL\n",
    "\n",
    "We will be saving the SVM model as it is 13% more accurate than the Decision Tree model. This process will avoid us going through the calculations again in the future if we want to categorise more reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "demonstrated-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/finalized_model.sav'\n",
    "\n",
    "#SAVING THE MODEL AND THE VECTORIZER\n",
    "pickle.dump(clf_svc, open(filename, 'wb'))\n",
    "pickle.dump(vectorizer, open('count_vect', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-lounge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
