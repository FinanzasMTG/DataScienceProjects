{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "suburban-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRARIES\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#DEFINING CLASSES\n",
    "class Sentiment:\n",
    "  NEGATIVE = 'NEGATIVE ðŸ”´'\n",
    "  POSITIVE = 'POSITIVE ðŸŸ¢'\n",
    "\n",
    "class Review:\n",
    "  def __init__(self,text,score):\n",
    "    self.text = text\n",
    "    self.score = score\n",
    "    self.sentiment = self.get_sentiment()\n",
    "\n",
    "  def get_sentiment(self):\n",
    "    if self.score == 0:\n",
    "      return Sentiment.NEGATIVE\n",
    "    else:\n",
    "      return Sentiment.POSITIVE\n",
    "\n",
    "class ReviewContainer:\n",
    "  def __init__(self, reviews):\n",
    "    self.reviews = reviews\n",
    "\n",
    "  def get_text(self):\n",
    "    return [x.text for x in self.reviews]\n",
    "\n",
    "  def get_sentiment(self):\n",
    "    return [x.sentiment for x in self.reviews]\n",
    "\n",
    "  def evenly_distribute(self):\n",
    "    negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "    positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "    positive_shrunk = positive[:2500]\n",
    "    negative_shrunk = negative[:2500]\n",
    "    self.reviews = negative_shrunk + positive_shrunk\n",
    "    random.shuffle(self.reviews)\n",
    "    \n",
    "def TestingReviews(amount=5):\n",
    "    list_rand = []\n",
    "    limit = len(test_data)\n",
    "    rand_row = random.randrange(amount, limit, 1)\n",
    "    for n in range(amount):\n",
    "        rand_row = random.randrange(0, limit, 1)\n",
    "        row_to_test = [test_data.user_review[rand_row]]\n",
    "        row_test = vectorizer.transform(row_to_test)\n",
    "        row_prediction = clf_svc.predict(row_test)[0]\n",
    "        row_proba = clf_svc.predict_proba(row_test)\n",
    "        row_max_proba = round(np.max(row_proba) * 100, 2)\n",
    "        print(\"Review: {}\".format(row_to_test))\n",
    "        print(\"Sentiment: {} - Confidence: {}%\".format(row_prediction, row_max_proba))\n",
    "        #print(clf_svc.predict(row_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-robin",
   "metadata": {},
   "source": [
    "### DEFINING AND PREPARING THE DATA\n",
    "\n",
    "We will load our train reviews (CSV file) and apply a filter to just use the two columns we need to train our model - user_suggestion and user_review. We will append the values using our Review class.\n",
    "\n",
    "We will also rename those columns to make it easier to work with them. If needed, we will need to evenly distribute values to avoid bias in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "least-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train_reviews.csv')\n",
    "\n",
    "#TEST DATA FOR FURTHER TESTING\n",
    "test_data = pd.read_csv('./data/test_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "worthy-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.rename(columns={\"recommendation\": \"score\", \"review\": \"text\"})\n",
    "df_train = df_train.filter(['text','score'])\n",
    "df_train['score'] = df_train['score'].replace('Not Recommended',0).replace('Recommended',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "super-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING SPECIAL CHARACTERS, WHICH MAY CONFUSE THE MODEL\n",
    "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "              \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\"]\n",
    "\n",
    "for char in spec_chars:\n",
    "    df_train['text'] = df_train['text'].str.replace(char, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "unavailable-salvation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "controlling-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "  reviews.append(Review(row['text'], row['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "subjective-coach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text\n",
       "score        \n",
       "0      130624\n",
       "1      302751"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('score').count() #MIGHT NEED TO BALANCE 0 AND 1 TO TRAIN THE MODEL BETTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-terminal",
   "metadata": {},
   "source": [
    "### DEFINING THE MODEL AND TRAINING\n",
    "\n",
    "From previous experience, a support-vector machine model provides the best results for user reviews. However, we will test Decision Trees too to evaluate the output with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "above-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = train_test_split(reviews, test_size=0.2, random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "usual-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment() \n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-corrections",
   "metadata": {},
   "source": [
    "#### VECTORISING THE DATA\n",
    "\n",
    "We will use a Count Vectorizer and a Tfidf Vectorizer and evaluate which delivers the best prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "infrared-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-tobago",
   "metadata": {},
   "source": [
    "#### SVM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "enhanced-constitutional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-fight",
   "metadata": {},
   "source": [
    "#### DECISION TREE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "express-threshold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 971 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-holly",
   "metadata": {},
   "source": [
    "#### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "concerned-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_nb = GaussianNB()\n",
    "# clf_nb.fit(train_x_vectors.todense(), train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-shock",
   "metadata": {},
   "source": [
    "#### MEAN ACCURACY OF EACH MODEL & F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bronze-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8278\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "#print(clf_dec.score(test_x_vectors, test_y))\n",
    "#print(clf_nb.score(test_x_vectors.todense(), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "imported-purpose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82797203 0.82762763]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "#print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "#print(f1_score(test_y, clf_nb.predict(test_x_vectors.todense()), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-defendant",
   "metadata": {},
   "source": [
    "### GRID SEARCH\n",
    "Optimising the model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "macro-fraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(probability=True),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'kernel': ('linear','rbf'), 'C': (1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC(probability=True)\n",
    "clf_svc = GridSearchCV(svc, parameters, cv=5)\n",
    "\n",
    "clf_svc.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "psychological-company",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829\n"
     ]
    }
   ],
   "source": [
    "print(clf_svc.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "extreme-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30,\n",
       "                                       40, 50, 70, 90, 120, 150]})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "\n",
    "clf_gridtree = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5)\n",
    "clf_gridtree.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "outstanding-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146\n"
     ]
    }
   ],
   "source": [
    "print(clf_gridtree.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-knife",
   "metadata": {},
   "source": [
    "### FURTHER TESTING\n",
    "\n",
    "You have to options to test the model: input your own text (a review) or runt the TestingReviews function and it will randomly pick X amount of indenpent reviews (not part of the training model) to categorise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "together-belize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: POSITIVE ðŸŸ¢ - Confidence: 68.2%\n"
     ]
    }
   ],
   "source": [
    "#SINGLE TESTING A SHORT REVIEW\n",
    "test_set = ['I was a bit confused about the gameplay so I didnt enjoyed the game this time, even though the sequel was great']\n",
    "\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "prediction = str(clf_svc.predict(new_test)[0])\n",
    "proba = clf_svc.predict_proba(new_test)\n",
    "max_proba = round(np.max(proba) * 100, 2)\n",
    "\n",
    "print(\"Sentiment: {} - Confidence: {}%\".format(prediction, max_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "personal-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: [\"Amazingly fun and addictive.I quickly fell in love with this game, as it has some of the following.Pro's:A no-loss system. You dont really lose much if you are wiped out.No need to make more ships, just repair the blown up ones and you are good to go.Lots of different loadouts for shipsSpace carriers. Mmmmmm.Alliance system.CoC like base raiding system, with a good bit of strategy involved.Noob protection is VERY good.Translator for many launguages.Semi-Good CommunityMultiplatform (Phone, computer, tablet, ect)Can use structures that are being upgraded, to a certain extent.Cons:Upgrade and building time can be a bit extreme at times.Several little hangups that some alliances use.Attack and defence system needs a group attack like system.Corvettes serve almost no purpose after very early levels.Fighters and carriers need to be MUCH more easy to get.Otherwise this game is amazing. LOVE IT.\"]\n",
      "Sentiment: POSITIVE ðŸŸ¢ - Confidence: 90.27%\n",
      "Review: ['Early Access ReviewGreat little game.  Reminds me a LOT of Hearthstone, only it\\'s better.  The animations and even strategy of where to place your units when starting battles add a whole extra dimension to the game.  Great variety of units and lot to learn to learn the nuances of which units counter which the best.It\\'s a great fast paced game with a lot of strategy.  It feels a little pay to win, but then that\\'s the way with pretty much all free 2 play games.  When you start ranking up you quickly run into players with much better cards.  However this is no different to almost every other F2P game and certainly no different to Hearthstone.  In short, well worth a visit.  Be warned it\\'s addictive as hell and definitely will cause you to say, \"just one more round\".']\n",
      "Sentiment: POSITIVE ðŸŸ¢ - Confidence: 95.49%\n",
      "Review: [\"Early Access ReviewDisappointing, the original Dungeon Defenders was a great game with a almost Nintendo like feel to it. Towards the end however it started to go down hill due to the developer vomiting paid DLC like a crack head trying to get money for a fix. Now we have this garbage in Early Access which is no where near as fun as the original and has over $100 in DLC already.Great to see indie devs taking a page from EA's book.\"]\n",
      "Sentiment: NEGATIVE ðŸ”´ - Confidence: 62.6%\n"
     ]
    }
   ],
   "source": [
    "#RUN THIS FUCTION (REVIEWS TO BE TESTED ARE 5 BY DEFAULT) TO TRY THE MODEL WITH A DIFFERENT REVIEWS DATASET\n",
    "TestingReviews(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-labor",
   "metadata": {},
   "source": [
    "### SAVING THE MODEL\n",
    "\n",
    "We will be saving the SVM model as it is 13% more accurate than the Decision Tree model. This process will avoid us going through the calculations again in the future if we want to categorise more reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "hawaiian-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/finalized_model.sav'\n",
    "\n",
    "#SAVING THE MODEL AND THE VECTORIZER\n",
    "pickle.dump(clf_svc, open(filename, 'wb'))\n",
    "pickle.dump(vectorizer, open('count_vect', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-triple",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
